\chapter{摘\texorpdfstring{\quad}{}要}
    近年来，移动机器人的应用场景和功能需求日益多样化和复杂化。自主导航能力是移动机器人实现其他复杂功能的前提条件，是最为关键的功能之一。当前，移动机器人普遍采用的自主导航技术主要依赖激光雷达，难以充分利用图像和语言等蕴含丰富特征的信息进行导航与避障。如何使移动机器人具备理解图像和语言的能力，并将其获取的点云信息同视觉与语义信息有效应用于自主导航，已成为亟待解决的难题。
    
    本文主要研究已知环境下多模态融合导航方法的研究及实现，提出了一种语言视觉激光多模态融合的机器人导航方法，并将其在真实的移动机器人上进行部署，构建了一套完整的已知环境下机器人视觉导航系统。
    针对在移动机器人室内导航过程中，单一使用视觉语言导航算法无法充分利用语义中的方位和环境中的感知信息、无法导航至目标半米内的问题，提出了一种语言视觉激光多模态融合的机器人导航方法。首先，在全局路径规划中，标记地图中的导航点，保留其位姿、图像、点云图和各点之间的拓扑信息，通过多模态融合网络得到各导航点与目标的匹配权值，结合dijkstra算法和方位优化算法，规划出全局路径导航点序列。然后，在局部路径规划中，通过特征提取、特征融合和运动模块在局部未知环境中探索目标，将多线激光与单目相机进行联合标定，进一步通过目标检测、点云聚类和坐标变换方法得到目标具体位姿，发布导航任务以完成局部路径的规划。最后，通过仿真实验和真实环境实验，验证所提出的导航方法的有效性和可行性。
    
    本文的主要贡献有以下几点：1）引入深度信息优化多模态融合网络，提高模型在光线条件变化大的室内的鲁棒性，提高导航点的正确率；2）提出了一种方位优化法，结合指令中提供的方位信息与移动机器人的实时位姿，筛选不符合方位条件的冗余导航点，再通过导航点规划算法进一步提高全局路径规划中导航点的正确率；3）设计并实现了一种单目相机和多线激光传感器融合的局部导航方法，以完成导航至目标半米内的闭环任务。

\keywordsCN{移动机器人；导航；多模态融合网络；方位优化；多传感器融合}

\chapter{Abstract}
    In recent years, the application scenarios and functional requirements of mobile robots have become increasingly diversified and complicated. Autonomous navigation ability is one of the most critical functions of mobile robot, which is the prerequisite for realizing other complex functions. At present, the autonomous navigation technology widely used by mobile robots mainly relies on LiDAR, which is difficult to make full use of the information containing rich features such as images and language for navigation and obstacle avoidance. How to make the mobile robot have the ability to understand images and language, and effectively apply the obtained point cloud information and visual and semantic information to autonomous navigation has become an urgent problem to be solved.

    This paper mainly studies the research and implementation of visual navigation methods in known environments, proposes a robot navigation method based on multi-modal fusion of language vision laser, and deploys it on real mobile robots to build a complete set of robot visual navigation systems in known environments.

    In order to solve the problem that the single visual language navigation algorithm can not make full use of the semantic orientation and the perceptual information in the environment, and can not navigate to the target within half a meter in the indoor navigation process of mobile robots, a multi-modal fusion of language vision laser navigation method is proposed. First of all, in global path planning, navigation points in the map are marked, their pose, image, point cloud image and topological information between points are retained, and the matching weights of each navigation point and the target are obtained through multi-modal fusion network. Combining dijkstra algorithm and orientation optimization algorithm, the global path navigation point sequence is planned. Then, in local path planning, the target is explored in the local unknown environment through feature extraction, feature fusion and motion module, the multi-line laser and monocular camera are jointly calibrated, and the specific pose of the target is obtained through target detection, point cloud clustering and coordinate transformation methods, and the navigation task is released to complete the local path planning. Finally, the effectiveness and feasibility of the proposed navigation method are verified by simulation experiments and real environment experiments.

    The main contributions of this paper are as follows: 1) Introduce deep information to optimize the multi-modal fusion network, improve the robustness of the model in the room with large changes in light conditions, and improve the accuracy of navigation points; 2) An orientation optimization method is proposed, which combines the orientation information provided in the instructions with the real-time pose of the mobile robot to screen the redundant navigation points that do not meet the orientation conditions, and then further improves the accuracy of navigation points in global path planning through the navigation point planning algorithm; 3) A local navigation method based on the fusion of monocular camera and multi-line laser sensor is designed and implemented to complete the closed-loop task of navigating to the target within half a meter.

\keywordsEN{Mobile Robot; Visual Navigation; Multi-Sensor Fusion; Multi-Modal Fusion Network; Orientation Optimization}