\chapter{摘\texorpdfstring{\quad}{}要}
    随着机器人需求市场的不断扩大，机器人逐渐从实验室跻身到酒店服务、工厂物流、家政服务、医疗看护、教育娱乐等各行各业之中，为推动生产力的持续发展做出了巨大贡献。在众多的应用场景之中移动机器人主要以室内环境作为其主要的工作场景，以自主导航作为其完成其他复杂任务的基础功能。目前大部分广泛应用于室内服务的移动机器人都采用点云激光进行建图与实时定位来实现自主导航，然而这种方法无法利用图像丰富的特征信息进行导航，容易在平坦、多重复场景这类特征不明显的环境中定位失败，已成为亟待解决的难题。
    针对在移动机器人室内导航过程中，单一使用视觉语言导航算法无法充分利用语义中的方位和环境中的感知信息、无法导航至目标半米内的问题，本文提出了一种语言视觉激光多模态融合的机器人导航方法。首先，在全局路径规划中，标记地图中的导航点，保留其位姿、图像、点云图和各点之间的拓扑信息，通过多模态融合网络得到各导航点与目标的匹配权值，结合dijkstra算法和方位优化算法，规划出全局路径导航点序列。然后在局部路径规划中，通过特征提取、特征融合和运动模块在局部未知环境中探索目标，将多线激光与单目相机进行联合标定，进一步通过目标检测、点云聚类和坐标变换方法得到目标具体位姿，发布导航任务以完成局部路径的规划。最后，通过仿真实验和真实环境实验，验证所提出的导航方法的有效性和可行性。
    本文的主要贡献如下：
\begin{enumerate}[topsep = 0 pt, itemsep= 0 pt, parsep=0pt, partopsep=0pt, leftmargin=44pt, itemindent=0pt, labelsep=6pt, label=(\arabic*)]
    \item 	本文提出了一种全局路径规划导航方法。与前人的工作相比，针对静态目标导航任务所提出的全局路径规划导航方法基于单目相机、激光雷达等多种传感器和基于多模态特征融合神经网络，增强系统对当前环境和导航过程中的认知和感知能力，再通过方位优化算法筛除噪声导航点，提高导航点选择的正确率的同时提高后续规划的计算响应速度，最后通过导航点规划算法加权融合多种策略进一步提高导航的准确率和导航效率。
    \item	本文提出了一种未知环境的目标物体探索方法。与前人的工作相比，针对动态目标导航任务所提出的局部目标物体探索方法基于多特征提取和融合的方法，在同一嵌入空间内利用注意力机制融合视觉特征和文本特征，有效的构建了视觉表示和目标物体所在导航方向的关联，使系统能够通过探索找到在变化的环境中的目标物体。
    \item	本文设计了一套单目相机和多线激光融合的图像点云融合方法，联合视觉观察的认知信息和多线点云的感知信息让移动机器人能够有效地在仿真环境和真实环境中依据自然语言指令完成目标导航任务，在仿真环境和真实机器人上部署并完成一系列可行性与性能测试，实验结果表明该方法具有一定的有效性和优越性。
\end{enumerate}

\keywordsCN{移动机器人；自主导航系统；多传感器融合；路径规划}

\chapter{Abstract}
    With the continuous expansion of the robot demand market, robots gradually from the laboratory to hotel services, factory logistics, domestic service, medical care, education and entertainment and other industries, to promote the sustainable development of productivity has made great contributions. In many application scenarios, the mobile robot mainly takes indoor environment as its main working scene, and autonomous navigation as its basic function to complete other complex tasks. At present, most of the mobile robots widely used in indoor services use point cloud laser for mapping and real-time positioning to achieve autonomous navigation. However, this method cannot make use of the rich feature information of images for navigation, and it is easy to fail to locate in the environment with unclear features such as flat and multiple repeated scenes, which has become an urgent problem to be solved.
    In order to solve the problem that the single visual language navigation algorithm can not make full use of the semantic orientation and the perceptual information in the environment, and can not navigate to the target within half a meter in the indoor navigation process of mobile robots, this paper proposes a multi-modal fusion robot navigation method based on language vision laser. First of all, in global path planning, navigation points in the map are marked, their pose, image, point cloud image and topological information between points are retained, and the matching weights of each navigation point and the target are obtained through multi-modal fusion network. Combining dijkstra algorithm and orientation optimization algorithm, the global path navigation point sequence is planned. Then, in local path planning, the target is explored in the local unknown environment through feature extraction, feature fusion and motion module, the multi-line laser and monocular camera are jointly calibrated, and the specific pose of the target is obtained through target detection, point cloud clustering and coordinate transformation methods, and the navigation task is released to complete the local path planning. Finally, the effectiveness and feasibility of the proposed navigation method are verified by simulation experiments and real environment experiments.
    The main contributions of this paper are as follows:
    \begin{enumerate}[topsep = 0 pt, itemsep= 0 pt, parsep=0pt, partopsep=0pt, leftmargin=44pt, itemindent=0pt, labelsep=6pt, label=(\arabic*)]
        \item 	This paper presents a global path planning navigation method. Compared with previous work, the proposed global path planning navigation method for static target navigation tasks is based on a variety of sensors such as monocular camera and Lidar and a multi-modal feature fusion neural network to enhance the system's cognition and perception of the current environment and navigation process, and then filters out the noise navigation points through the orientation optimization algorithm. The accuracy rate of navigation point selection is improved, and the computational response speed of subsequent planning is improved. Finally, the navigation accuracy and efficiency are further improved through the weighted integration of navigation point planning algorithms.
        \item	This paper proposes an exploration method for target objects in an unknown environment. Compared with previous works, the local target object exploration method proposed for the dynamic target navigation task is based on the method of multi-feature extraction and fusion. Within the same embedding space, the attention mechanism is utilized to fuse visual features and text features, effectively constructing the association between the visual representation and the navigation direction where the target object is located. Enable the system to find the target objects in the changing environment through exploration.
        \item	In this paper, a set of image point cloud fusion method based on monocular camera and multi-line laser fusion is designed. By combining cognitive information of visual observation and perception information of multi-line point cloud, the mobile robot can effectively complete target navigation tasks according to natural language instructions in simulation environment and real environment, and a series of feasibility and performance tests are deployed and completed on simulation environment and real robot. The experimental results show that this method has certain effectiveness and superiority.
    \end{enumerate}


\keywordsEN{Mobile Robot; Autonomous Navigation System; Multi-Sensor Fusion; Path planning}